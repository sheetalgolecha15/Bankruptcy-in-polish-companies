---
title: "Rose"
author: "Sheetal Shraddha"
date: "2/7/2019"
output: html_document
---

```{r setup, include=FALSE}
library(mice)
library(DMwR)
library(corrplot)
library(randomForest)
library(e1071)
library(caret)
library(rpart)
library(ROSE)
library(C50)
library(dplyr)
require(MASS)
require(ggplot2)
require(scales)
library(class)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
df<-read.csv("subset.csv")
df=subset(df, select = -c(X) )

df_rose <- ROSE(V65~ ., data=df, p=0.05,seed=111)$data
df_rose <- df_rose[sample(nrow(df_rose)),]
train_rose=df_rose[1:32550,]

test_rose=df_rose[32551:43405,]
```

LIke the previous file classification on dataset we will run all the model same has that file.
```{r}
Logit_model=glm(V65~.,family="binomial",data=train_rose)
#summary(Logit_model)
logit_predict_train=predict(Logit_model,train_rose,type='response')
logit_predict_test=predict(Logit_model,test_rose,type='response')
confusionMatrix(table(as.numeric(logit_predict_train>0.5),train_rose$V65))
confusionMatrix(table(as.numeric(logit_predict_test>0.5),test_rose$V65))
```
Sensitivity is good but the specificty is bad

Cant run Negative binomial,poisson,zero inflation or hurdle as the rose model generates negative values on the dataset, so we just ran the othe algorithm.
```{r}
train_rose$V65=as.factor(train_rose$V65)
test_rose$V65=as.factor(test_rose$V65)

Classify=naiveBayes(train_rose[,1:34],train_rose[,35],laplace=1)
naive_predict_train<-predict(Classify, train_rose[,1:34])
naive_predict_test<-predict(Classify, test_rose[,1:34])
confusionMatrix(table(naive_predict_train,train_rose$V65))
confusionMatrix(table(naive_predict_test,test_rose$V65))
```
The sensitivity and specificiy of both train and test data is good in naive bayers algorithm.
```{r}
lda1 <- lda(V65 ~ ., data = train_rose)

lda_predict_train<-as.data.frame(predict(lda1, train_rose[,1:34],type="response"))$class
lda_predict_test<-as.data.frame(predict(lda1, test_rose[,1:34],type="response"))$class
confusionMatrix(table(lda_predict_train,train_rose$V65))
confusionMatrix(table(lda_predict_test,test_rose$V65))
```
Lda doesnt give good accuracy either.
```{r}
train_rose$V65=as.factor(train_rose$V65)
test_rose$V65=as.factor(test_rose$V65)
c5_rules <- C5.0(V65 ~ V1+V2+V4+V5+V7+V8+V9+V10+V12+V13+V15+V17+V21+V27+V28+V29+V30+V32+V33+V37+V39+V40+V41
                 +V42+V47+V52+V53+V54+V55+V57+V59+V60+V61 , train_rose)
dt_predict_train<-predict(c5_rules, train_rose[,1:34])
dt_predict_test<-predict(c5_rules, test_rose[,1:34])
confusionMatrix(table(dt_predict_train,train_rose$V65))
confusionMatrix(table(dt_predict_test,test_rose$V65))
```
Sensitivity and specificity is good for decision tree.

```{r pressure, echo=FALSE}
rfm_model = randomForest(V65 ~ ., data = train_rose)
rfm_predict_train<-as.data.frame(predict(rfm_model, train_rose[,1:34],type="prob"))
rfm_predict_test<-as.data.frame(predict(rfm_model, test_rose[,1:34],type="prob"))
head(rfm_predict_train)
colnames(rfm_predict_train)[2] <- "predict"
colnames(rfm_predict_test)[2] <- "predict"
confusionMatrix(table(as.numeric(rfm_predict_train$predict>0.5),train_rose$V65))
confusionMatrix(table(as.numeric(rfm_predict_test$predict>0.5),test_rose$V65))
```

```{r}
svmfit = svm(V65 ~ ., data = train_rose, kernel = "sigmoid", cost = 10, scale = FALSE)
svm_predict_train<-as.data.frame(predict(svmfit, train_rose[,1:34],type="prob"))
svm_predict_test<-as.data.frame(predict(svmfit, test_rose[,1:34],type="prob"))
colnames(svm_predict_test)[1] <- "predict"
colnames(svm_predict_train)[1] <- "predict"
confusionMatrix(table(svm_predict_train$predict,train_rose$V65))
confusionMatrix(table(svm_predict_test$predict,test_rose$V65))
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
